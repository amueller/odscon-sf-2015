{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of core text classification with the Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Amazon movie reviews collected by J. McAuley and J. Leskovec\n",
    "\n",
    "https://snap.stanford.edu/data/web-Movies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"file size: %d GB\" % (os.path.getsize(\"data/movies.txt\") / 1024 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/movies.txt\") as f:\n",
    "    print(f.read(4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_iter(f):\n",
    "    current_post = []\n",
    "    for line in f:\n",
    "        if line.startswith(\"product/productId\"):\n",
    "            if len(current_post):\n",
    "                score = current_post[3].strip(\"review/score: \").strip()\n",
    "                review = \"\".join(current_post[6:]).strip(\"review/text: \").strip()\n",
    "                # there are about 20 posts with linebreaks in them.\n",
    "                # we just ignore those for simplicity\n",
    "                try:\n",
    "                    yield int(float(score)), review\n",
    "                except:\n",
    "                    current_post = []\n",
    "                    continue\n",
    "            current_post = []\n",
    "        else:\n",
    "            current_post.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_reviews = 0\n",
    "with open(\"data/movies.txt\", 'r', errors='ignore') as f:\n",
    "    for r in review_iter(f):\n",
    "        n_reviews += 1\n",
    "\n",
    "print(\"Number of reviews: %d\" % n_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "with open(\"data/movies.txt\", 'rb') as f:\n",
    "    reviews = islice(review_iter(f), 10000)\n",
    "    scores, texts = zip(*reviews)\n",
    "print(np.bincount(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import zip_longest # use izip_longest on Python3\n",
    "# from the itertools recipes\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue=fillvalue, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_batch(reviews):\n",
    "    # score == 3 is \"neutral\", we only want \"positive\" or \"negative\"\n",
    "    reviews_filtered = [r for r in reviews if r is not None and r[0] != 3]\n",
    "    scores, texts = zip(*reviews_filtered)\n",
    "    polarity = np.array(scores) > 3\n",
    "    return polarity, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer = HashingVectorizer(decode_error=\"ignore\")\n",
    "\n",
    "with open(\"data/movies.txt\") as f:\n",
    "    reviews = islice(review_iter(f), 10000)\n",
    "    polarity_test, texts_test = preprocess_batch(reviews)\n",
    "    X_test = vectorizer.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(random_state=0)\n",
    "\n",
    "accuracies = []\n",
    "with open(\"data/movies.txt\") as f:\n",
    "    training_set = islice(review_iter(f), 10000, None)\n",
    "    batch_iter = grouper(training_set, 10000)\n",
    "    for batch in batch_iter:\n",
    "        polarity, texts = preprocess_batch(batch)\n",
    "        X = vectorizer.transform(texts)\n",
    "        sgd.partial_fit(X, polarity, classes=[0, 1])\n",
    "        accuracies.append(sgd.score(X_test, polarity_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
